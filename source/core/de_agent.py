# import openai
# from llama_index.agent.openai import OpenAIAgent
# import os
# from langchain.memory import ConversationBufferMemory
# from llama_index import GPTVectorStoreIndex
# from langchain.chat_models import OpenAI
import logging
# from io import BytesIO
import sys
# import re

# from typing import List, Dict, Union
from agents import ChatLLMOpenAI

logger = logging.getLogger("AppLogger")

# def init_de_agent(user_api_key: str, role_prompt: str) -> ChatLLMOpenAI:

#     """
#     Initialize the domain expert agent with langchain memory and user provided api key.
#     Assign role to agent via passed argument
#     Args:
#         user_api_key (str): The api key entered by the user
#         role_prompt (str): the role prompt for de agent
#     Returns:
#         ChatLLMOpenAI: the de agent  
    
#     Raises:
#         Exception: Logs and exits the program if an error occurs during execution.

#     """
#     try:
#         # Initialize agent
#         de_agent = ChatLLMOpenAI(user_api_key=user_api_key, role_prompt=role_prompt)
        
#         return de_agent
#     # Initialize agent role
#     except Exception as e:
#         logger.error("An error has occurred in initializing de agent: ", e)
#         # logging.info(e)

#         sys.exit()
    
def generate_eda_questions(agent: ChatLLMOpenAI, df_sample, metadata):

    """
    Generate coding prompts for the EDA process based on the dataset and its metadata.

    This function leverages an AI agent to create 10 exploratory data analysis (EDA) prompts that 
    identify relationships, patterns, clusters, and correlations in the provided dataset. These 
    prompts are intended for coders to execute EDA tasks effectively.

    Args:
        agent (ChatLLMOpenAI): The AI agent responsible for generating the questions.
        files (List[Dict[str, BytesIO]]): A list of file metadata, where each file is represented 
                                          as a dictionary with keys 'name' (str) and 'content' (BytesIO).
        metadata (List[Dict[str, str]]): Metadata describing the dataset, including column details and 
                                         data summaries.

    Returns:
        List[str]: A list of 10 EDA-related prompts for coders.

    Raises:
        Exception: Logs and exits the program if an error occurs during execution.
    """

    try:
        prompt = f"""
            You are a domain expert and data scientist tasked with performing Exploratory Data Analysis (EDA) on the provided dataset. 
            Your goal is to identify key relationships, patterns, clusters, correlations, and insights that are essential for the analysis.

            - **Provided Dataframe sample containing a random subset of the full dataset:** 
            <data_files>{df_sample}</data_files>

            - **Dataset Description and Metadata:**
            <metadata>{metadata}</metadata>

            Based on your expertise:
            1. Generate 3 well-defined prompts as bullet points for coders. 
            2. Each prompt should focus on exploring interesting patterns, trends, and relationships in the dataset that are crucial for the EDA process.
            3. Ensure the prompts cover both qualitative and quantitative aspects of the data.

            Make the prompts clear, actionable, and relevant to the provided context.
            """

        response = agent.prompt_agent(prompt)#["content"]
        return response

        # # parse response to create list
        # bullet_point_pattern = r"^- (.+)$"
        # # Parse the text and extract the bullet points
        # questions = re.findall(bullet_point_pattern, response, re.MULTILINE)

        return questions
    except Exception as e:
        logger.error("An error has occurred in generating coding prompts for ci agent task: ", e)
        sys.exit()
        

def analyse_eda_output(agent: ChatLLMOpenAI, qa_list):

    """
    Analyze the outputs generated by coders during the EDA process.

    This function uses an AI agent to analyze the answers to EDA-related questions. Based on the 
    coder's outputs and the corresponding queries, the function provides insightful observations 
    and conclusions about the results.

    Args:
        agent (ChatLLMOpenAI): The AI agent responsible for generating the analysis.
        qa_list (List[Dict[str, str]]): A list of dictionaries, where each dictionary contains:
            - "question" (str): The EDA-related question.
            - "code_answer" (str): The answer provided by the coder.

    Returns:
        List[Dict[str, str, str]]: A list of dictionaries containing:
            - "question" (str): The original question.
            - "code_answer" (str): The coder's answer to the question.
            - "output_analysis" (str): The agent's analysis and conclusions based on the coder's output.

    Raises:
        Exception: Logs and exits the program if an error occurs during execution.
    """

    analysis_list = []
    
    try:
        for item in qa_list:

            prompt = f"""
                The coder has provided an answer to your query. Below is the relevant query and its corresponding answer. 
                Note: Answers involving charts contain a base64 encoded image. You should interpret and analyze it as part of your response.

                <question>{item["question"]}</question>
                <answer>{item["answer"]}</answer>

                Using your domain expertise:
                1. Carefully analyze the provided answer, including any base64 encoded charts or images.
                2. Identify key insights, patterns, or conclusions derived from the output.
                3. Summarize your observations and provide actionable recommendations or conclusions to enhance understanding.

                Your analysis should be:
                - Comprehensive and insightful.
                - Concise, focusing only on relevant details.
                - Structured to add clear value to the understanding of the query's results.
                """



            res = agent.prompt_agent(prompt)
            analysis_list.append({"question": item["question"], "code_answer": item["answer"], "answer_analysis": res})
        return analysis_list
    except Exception as e:
        logger.error("An error has occurred in analysing eda output: ", e)
        sys.exit()


        

